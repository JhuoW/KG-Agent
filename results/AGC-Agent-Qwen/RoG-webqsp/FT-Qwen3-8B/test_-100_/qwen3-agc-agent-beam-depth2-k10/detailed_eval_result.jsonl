{"id": "WebQTest-0", "prediction": ["# Reasoning Path:\nJamaica\n# Answer:\nJamaican Creole English Language", "# Reasoning Path:\nJamaica -> location.country.languages_spoken -> Jamaican Creole English Language -> language.human_language.countries_spoken_in -> Costa Rica\n# Answer:\nJamaican Creole English Language", "# Reasoning Path:\nJamaica -> location.country.languages_spoken -> Jamaican Creole English Language -> language.human_language.region -> Americas\n# Answer:\nJamaican Creole English Language"], "ground_truth": ["Jamaican English", "Jamaican Creole English Language"], "ans_acc": 0.5, "ans_hit": 1, "ans_f1": 0.6666666666666666, "ans_precission": 1.0, "ans_recall": 0.5, "path_f1": 0.5714285714285715, "path_precision": 0.6666666666666666, "path_recall": 0.5, "path_ans_f1": 0.5714285714285715, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 0.5}
{"id": "WebQTest-1", "prediction": ["# Reasoning Path:\nJames K. Polk\n# Answer:\nJames K. Polk"], "ground_truth": ["United States Representative", "Governor of Tennessee", "Speaker of the United States House of Representatives"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-100", "prediction": ["# Reasoning Path:\nHaiti\n# Answer:\nHaitian Creole", "# Reasoning Path:\nHaiti -> location.country.languages_spoken -> Haitian Creole\n# Answer:\nHaitian Creole", "# Reasoning Path:\nHaiti -> location.country.languages_spoken -> French -> language.human_language.countries_spoken_in -> France\n# Answer:\nFrench", "# Reasoning Path:\nHaiti -> location.country.languages_spoken -> French -> language.human_language.countries_spoken_in -> Martinique\n# Answer:\nFrench", "# Reasoning Path:\nHaiti -> location.country.languages_spoken -> French -> language.human_language.main_country -> France\n# Answer:\nFrench", "# Reasoning Path:\nHaiti -> location.country.languages_spoken -> French -> language.human_language.region -> Europe\n# Answer:\nFrench"], "ground_truth": ["Haitian Creole", "French"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.25, "path_precision": 0.16666666666666666, "path_recall": 0.5, "path_ans_f1": 0.9090909090909091, "path_ans_precision": 0.8333333333333334, "path_ans_recall": 1.0}
{"id": "WebQTest-102", "prediction": ["# Reasoning Path:\nBarbara Gordon\n# Answer:\nBarbara Gordon"], "ground_truth": ["Ilyssa Fradin", "Melinda McGraw", "Hannah Gunn"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-103", "prediction": ["# Reasoning Path:\nShaquille O'Neal\n# Answer:\nShaquille O'Neal"], "ground_truth": ["Phoenix Suns", "Los Angeles Lakers", "Orlando Magic", "Miami Heat", "LSU Tigers men's basketball", "Boston Celtics", "Cleveland Cavaliers"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-104", "prediction": ["# Reasoning Path:\nJay Leno\n# Answer:\nNew Rochelle", "# Reasoning Path:\nJay Leno -> people.person.place_of_birth -> New Rochelle -> location.hud_county_place.county -> Westchester County\n# Answer:\nNew Rochelle", "# Reasoning Path:\nJay Leno -> people.person.place_of_birth -> New Rochelle -> base.biblioness.bibs_location.state -> New York\n# Answer:\nNew Rochelle", "# Reasoning Path:\nJay Leno -> people.person.place_of_birth -> New Rochelle -> common.topic.subject_of -> iFix iBuy\n# Answer:\nNew Rochelle"], "ground_truth": ["New Rochelle"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.8571428571428571, "path_precision": 0.75, "path_recall": 1.0, "path_ans_f1": 0.8571428571428571, "path_ans_precision": 0.75, "path_ans_recall": 1.0}
{"id": "WebQTest-105", "prediction": ["# Reasoning Path:\nThailand\n# Answer:\nThai Language", "# Reasoning Path:\nThailand -> location.country.languages_spoken -> Thai Language\n# Answer:\nThai Language", "# Reasoning Path:\nThailand -> location.country.official_language -> Thai Language -> media_common.netflix_genre.titles -> Shutter\n# Answer:\nThai Language", "# Reasoning Path:\nThailand -> location.country.official_language -> Thai Language -> language.human_language.region -> Asia\n# Answer:\nThai Language"], "ground_truth": ["Vietnamese Language", "Akha Language", "Khmer language", "Mon Language", "Mlabri Language", "Saek language", "Nyaw Language", "Thai Language", "Hmong language", "Phu Thai language", "Lao Language", "Malay, Pattani Language", "Cham language"], "ans_acc": 0.07692307692307693, "ans_hit": 1, "ans_f1": 0.14285714285714288, "ans_precission": 1.0, "ans_recall": 0.07692307692307693, "path_f1": 0.11764705882352941, "path_precision": 0.25, "path_recall": 0.07692307692307693, "path_ans_f1": 0.13953488372093026, "path_ans_precision": 0.75, "path_ans_recall": 0.07692307692307693}
{"id": "WebQTest-106", "prediction": ["# Reasoning Path:\nThe Social Network\n# Answer:\nThe Social Network"], "ground_truth": ["Cameron Winklevoss", "Tyler Winklevoss"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-107", "prediction": ["# Reasoning Path:\nThomas Jefferson\n# Answer:\nThomas Jefferson"], "ground_truth": ["Lawyer", "Statesman", "Architect", "Farmer", "Philosopher", "Teacher", "Inventor", "Author", "Archaeologist", "Writer"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-108", "prediction": ["# Reasoning Path:\nCharles Darwin\n# Answer:\nCharles Darwin"], "ground_truth": ["Journal of researches into the natural history and geology of the countries visited during the voyage round the world of the H. M. S. 'Beagle' under the command of Captain Fitz Roy, R. N", "The Correspondence of Charles Darwin, Volume 6", "The Correspondence of Charles Darwin, Volume 14: 1866", "Evolution", "The Origin of Species (Oxford World's Classics)", "The Correspondence of Charles Darwin, Volume 3", "The Different Forms of Flowers on Plants of the Same Species", "On a remarkable bar of sandstone off Pernambuco", "The Correspondence of Charles Darwin, Volume 14", "Darwin", "Der Ausdruck der Gem\u00fcthsbewegungen bei dem Menschen und den Thieren", "The Correspondence of Charles Darwin, Volume 11", "The Correspondence of Charles Darwin, Volume 13: 1865", "The Voyage of the Beagle (Everyman Paperbacks)", "Die geschlechtliche Zuchtwahl", "Letters from C. Darwin, Esq., to A. Hancock, Esq", "Charles Darwin's zoology notes & specimen lists from H.M.S. Beagle", "ontstaan der soorten door natuurlijke teeltkeus", "Het uitdrukken van emoties bij mens en dier", "The\u0301orie de l'e\u0301volution", "Darwin-Wallace", "Charles Darwin, 1809-1882--Anton Dohrn, 1840-1909", "The collected papers of Charles Darwin", "The Origin of Species (Mentor)", "The Correspondence of Charles Darwin, Volume 9: 1861", "The expression of the emotions in man and animals.", "Voyage of the Beagle (Harvard Classics, Part 29)", "The Voyage of the Beagle (Adventure Classics)", "Motsa ha-minim", "Notes on the fertilization of orchids", "The Autobiography of Charles Darwin", "Origin of Species (Harvard Classics, Part 11)", "The expression of the emotions in man and animals", "Les moyens d'expression chez les animaux", "The Essential Darwin", "The education of Darwin", "Proiskhozhdenie vidov", "Wu zhong qi yuan", "The Correspondence of Charles Darwin, Volume 17: 1869", "The Correspondence of Charles Darwin, Volume 13", "The origin of species", "Das Variiren der Thiere und Pflanzen im Zustande der Domestication", "The living thoughts of Darwin", "The Autobiography of Charles Darwin (Large Print)", "Charles Darwin's letters", "The Power of Movement in Plants", "Geological Observations on South America", "The Expression Of The Emotions In Man And Animals", "The Correspondence of Charles Darwin, Volume 15: 1867", "On Natural Selection", "Volcanic Islands", "The Structure and Distribution of Coral Reefs", "Gesammelte kleinere Schriften", "Diario del Viaje de Un Naturalista Alrededor", "The Correspondence of Charles Darwin, Volume 3: 1844-1846", "The Darwin Reader Second Edition", "The action of carbonate of ammonia on the roots of certain plants", "Evolution and natural selection", "The Correspondence of Charles Darwin, Volume 7", "\u00dcber die Wege der Hummel-M\u00e4nnchen", "Reise um die Welt 1831 - 36", "From Darwin's unpublished notebooks", "The Voyage of the Beagle (Unabridged Classics)", "genese\u014ds t\u014dn eid\u014dn", "Un m\u00e9moire in\u00e9dit de Charles Darwin sur l'instinct", "The Correspondence of Charles Darwin, Volume 18: 1870", "Die Bewegungen und Lebensweise der kletternden Pflanzen", "Notebooks on transmutation of species", "Darwin's notebooks on transmutation of species", "The Origin of Species (Great Books : Learning Channel)", "Beagle letters", "Voyage of the Beagle", "The Descent Of Man And Selection In Relation To Sex (Kessinger Publishing's Rare Reprints)", "The Origin of Species (Enriched Classics)", "The Correspondence of Charles Darwin, Volume 12: 1864", "The Life of Erasmus Darwin", "The Autobiography of Charles Darwin, and selected letters", "The structure and distribution of coral reefs", "Die Entstehung der Arten durch nat\u00fcrliche Zuchtwahl", "The Expression of the Emotions in Man and Animals (Large Print Edition): The Expression of the Emotions in Man and Animals (Large Print Edition)", "The voyage of the Beagle.", "Descent of Man and Selection in Relation to Sex (Barnes & Noble Library of Essential Reading)", "Memorias y epistolario i\u0301ntimo", "Del Plata a Tierra del Fuego", "El Origin De Las Especies", "The Autobiography Of Charles Darwin", "The Autobiography of Charles Darwin [EasyRead Comfort Edition]", "On the tendency of species to form varieties", "The descent of man, and selection in relation to sex", "THE ORIGIN OF SPECIES (Wordsworth Collection) (Wordsworth Collection)", "The portable Darwin", "Monographs of the fossil Lepadidae and the fossil Balanidae", "\u00dcber den Bau und die Verbreitung der Corallen-Riffe", "The Origin of Species (Great Minds Series)", "Darwin's insects", "Charles Darwin's natural selection", "Works", "Fertilisation of Orchids", "The Autobiography of Charles Darwin (Dodo Press)", "The Correspondence of Charles Darwin, Volume 16: 1868", "The Correspondence of Charles Darwin, Volume 10: 1862", "vari\u00eberen der huisdieren en cultuurplanten", "From So Simple a Beginning", "The Effects of Cross and Self Fertilisation in the Vegetable Kingdom", "Autobiography of Charles Darwin", "To the members of the Down Friendly Club", "Insectivorous Plants", "The Autobiography of Charles Darwin (Great Minds Series)", "Voyage d'un naturaliste autour du monde", "The Correspondence of Charles Darwin, Volume 5", "La facult\u00e9 motrice dans les plantes", "The Formation of Vegetable Mould through the Action of Worms", "The Correspondence of Charles Darwin, Volume 7: 1858-1859", "The Correspondence of Charles Darwin, Volume 1: 1821-1836", "The origin of species : complete and fully illustrated", "Darwin on humus and the earthworm", "Darwin Darwin", "A student's introduction to Charles Darwin", "The Correspondence of Charles Darwin, Volume 15", "Questions about the breeding of animals", "The principal works", "The Autobiography of Charles Darwin [EasyRead Edition]", "Darwinism stated by Darwin himself", "Die fundamente zur entstehung der arten", "The Orgin of Species", "The Variation of Animals and Plants under Domestication", "The Correspondence of Charles Darwin, Volume 9", "H.M.S. Beagle in South America", "Voyage Of The Beagle", "The Correspondence of Charles Darwin, Volume 11: 1863", "The Correspondence of Charles Darwin, Volume 8", "Origins", "Darwin for Today", "Part I: Contributions to the Theory of Natural Selection / Part II", "The autobiography of Charles Darwin", "Tesakneri tsagume\u030c", "La vie et la correspondance de Charles Darwin", "Rejse om jorden", "The Voyage of the Beagle (Classics of World Literature) (Classics of World Literature)", "The Origin of Species (Collector's Library)", "Kleinere geologische Abhandlungen", "On the Movements and Habits of Climbing Plants", "Reise eines Naturforschers um die Welt", "Evolution by natural selection", "The Correspondence of Charles Darwin, Volume 5: 1851-1855", "Die Wirkungen der Kreuz- und Selbst-Befruchtung im Pflanzenreich", "Opsht\u0323amung fun menshen", "Charles Darwin on the routes of male humble bees", "The descent of man, and selection in relation to sex.", "Darwin's journal", "The Voyage of the Beagle (Great Minds Series)", "The Voyage of the Beagle", "The Correspondence of Charles Darwin, Volume 4: 1847-1850", "The Correspondence of Charles Darwin, Volume 2", "The Structure And Distribution of Coral Reefs", "The Descent of Man, and Selection in Relation to Sex", "The foundations of the Origin of species", "Metaphysics, Materialism, & the evolution of mind", "The Expression of the Emotions in Man and Animals", "Charles Darwin", "monograph on the sub-class Cirripedia", "The Correspondence of Charles Darwin, Volume 12", "The Correspondence of Charles Darwin, Volume 1", "Les mouvements et les habitudes des plantes grimpantes", "The Correspondence of Charles Darwin, Volume 4", "La descendance de l'homme et la s\u00a9\u00d8election sexuelle", "The Correspondence of Charles Darwin, Volume 2: 1837-1843", "Die verschiedenen Bl\u00fctenformen an Pflanzen der n\u00e4mlichen Art", "The Expression of the Emotions in Man And Animals", "The Correspondence of Charles Darwin, Volume 10", "The Origin Of Species", "The Origin of Species", "Darwin en Patagonia", "The Autobiography of Charles Darwin [EasyRead Large Edition]", "The Origin of Species (World's Classics)", "Geological observations on the volcanic islands and parts of South America visited during the voyage of H.M.S. 'Beagle", "Darwin and Henslow", "Leben und Briefe von Charles Darwin", "On evolution", "The origin of species by means of natural selection, or, The preservation of favored races in the struggle for life", "The Voyage of the Beagle (Mentor)", "The geology of the voyage of H.M.S. Beagle", "Voyage of the Beagle (NG Adventure Classics)", "The Descent of Man and Selection in Relation to Sex", "The voyage of Charles Darwin", "Voyage of the Beagle (Dover Value Editions)", "The autobiography of Charles Darwin, 1809-1882", "Origin of Species (Everyman's University Paperbacks)", "Viaje de Un Naturalista Alrededor del Mundo 2 Vol", "Origin of Species", "The Darwin Reader First Edition", "Vospominanii\ufe20a\ufe21 o razvitii moego uma i kharaktera", "Cartas de Darwin 18251859", "The Correspondence of Charles Darwin, Volume 8: 1860", "The Origin of Species (Barnes & Noble Classics Series) (Barnes & Noble Classics)", "Human nature, Darwin's view", "red notebook of Charles Darwin", "Seul celui qui change reste fid\u00e8le \u00e0 lui-m\u00eame", "From so simple a beginning", "More Letters of Charles Darwin", "On the origin of species by means of natural selection", "Les r\u00e9cifs de corail, leur structure et leur distribution", "The Origin of Species (Variorum Reprint)", "The structure and distribution of coral reefs.", "Darwin's Ornithological notes", "A Darwin Selection", "Darwin Compendium", "Charles Darwin's marginalia", "The Correspondence of Charles Darwin, Volume 6: 1856-1857", "Resa kring jorden", "The descent of man and selection in relation to sex.", "The Voyage of the \\\"Beagle\\\" (Everyman's Classics)", "Diary of the voyage of H.M.S. Beagle", "The zoology of the voyage of H.M.S. Beagle during the years 1832-1836"], "ans_acc": 0.009345794392523364, "ans_hit": 1, "ans_f1": 0.018518518518518517, "ans_precission": 1.0, "ans_recall": 0.009345794392523364, "path_f1": 0.06666666666666667, "path_precision": 1.0, "path_recall": 0.034482758620689655, "path_ans_f1": 0.018518518518518517, "path_ans_precision": 1.0, "path_ans_recall": 0.009345794392523364}
{"id": "WebQTest-109", "prediction": ["# Reasoning Path:\nTim Tebow\n# Answer:\nTim Tebow"], "ground_truth": ["Florida Gators football"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-110", "prediction": ["# Reasoning Path:\nPeyton Manning\n# Answer:\nPeyton Manning"], "ground_truth": ["Denver Broncos"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-111", "prediction": ["# Reasoning Path:\nCarpathian Mountains\n# Answer:\nCarpathian Mountains"], "ground_truth": ["Europe"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-112", "prediction": ["# Reasoning Path:\nRobert Burns\n# Answer:\nRobert Burns (1759\u20131796)", "# Reasoning Path:\nRobert Burns -> visual_art.art_subject.artwork_on_the_subject -> Robert Burns (1759\u20131796) -> visual_art.artwork.artist -> Alexander Nasmyth\n# Answer:\nRobert Burns (1759\u20131796)", "# Reasoning Path:\nRobert Burns -> visual_art.art_subject.artwork_on_the_subject -> Robert Burns (1759\u20131796) -> common.topic.notable_types -> Artwork\n# Answer:\nRobert Burns (1759\u20131796)"], "ground_truth": ["Bard", "Writer", "Author", "Poet"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-114", "prediction": ["# Reasoning Path:\nDarth Vader\n# Answer:\nDarth Vader"], "ground_truth": ["Hayden Christensen"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-115", "prediction": ["# Reasoning Path:\nPeyton Manning\n# Answer:\nPeyton Manning"], "ground_truth": ["Super Bowl XLI"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-116", "prediction": ["# Reasoning Path:\nJustin Bieber\n# Answer:\nCanada", "# Reasoning Path:\nJustin Bieber -> people.person.nationality -> Canada\n# Answer:\nCanada"], "ground_truth": ["Canada"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-118", "prediction": ["# Reasoning Path:\nGulf War\n# Answer:\nGulf War"], "ground_truth": ["Australia", "France", "United States of America", "Saudi Arabia", "Iraq", "United Kingdom", "Argentina"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-119", "prediction": ["# Reasoning Path:\nThe Suite Life on Deck\n# Answer:\nThe Suite Life on Deck"], "ground_truth": ["Brenda Song"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-12", "prediction": ["# Reasoning Path:\nOhio\n# Answer:\nOhio"], "ground_truth": ["Return J. Meigs, Jr.", "Ted Strickland", "John Kasich"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-121", "prediction": ["# Reasoning Path:\nDavid Beckham\n# Answer:\nDavid Beckham"], "ground_truth": ["LA Galaxy"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-122", "prediction": ["# Reasoning Path:\nFrancisco V\u00e1zquez de Coronado\n# Answer:\nFrancisco V\u00e1zquez de Coronado"], "ground_truth": ["Salamanca"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-13", "prediction": ["# Reasoning Path:\nJohn F. Kennedy\n# Answer:\nJohn F. Kennedy"], "ground_truth": ["Lyndon B. Johnson"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-14", "prediction": ["# Reasoning Path:\nFukushima Daiichi Nuclear Power Plant\n# Answer:\nJapan", "# Reasoning Path:\nFukushima Daiichi Nuclear Power Plant -> location.location.containedby -> Japan\n# Answer:\nJapan"], "ground_truth": ["Okuma", "Japan"], "ans_acc": 0.5, "ans_hit": 1, "ans_f1": 0.6666666666666666, "ans_precission": 1.0, "ans_recall": 0.5, "path_f1": 0.5, "path_precision": 0.5, "path_recall": 0.5, "path_ans_f1": 0.5, "path_ans_precision": 0.5, "path_ans_recall": 0.5}
{"id": "WebQTest-16", "prediction": ["# Reasoning Path:\nUnited Kingdom\n# Answer:\nUnited Kingdom"], "ground_truth": ["Scotland", "Northern Ireland", "Wales", "England"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-19", "prediction": ["# Reasoning Path:\nLouisiana\n# Answer:\nLouisiana"], "ground_truth": ["Central Time Zone"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-20", "prediction": ["# Reasoning Path:\nAugustine of Hippo\n# Answer:\nAugustine of Hippo"], "ground_truth": ["Writer", "Physician", "Philosopher"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-21", "prediction": ["# Reasoning Path:\nKeyshia Cole\n# Answer:\nLeon Cole", "# Reasoning Path:\nKeyshia Cole -> people.person.parents -> Leon Cole\n# Answer:\nLeon Cole"], "ground_truth": ["Francine Lons", "Leon Cole", "Sal Gibson"], "ans_acc": 0.3333333333333333, "ans_hit": 1, "ans_f1": 0.5, "ans_precission": 1.0, "ans_recall": 0.3333333333333333, "path_f1": 0.4, "path_precision": 0.5, "path_recall": 0.3333333333333333, "path_ans_f1": 0.4, "path_ans_precision": 0.5, "path_ans_recall": 0.3333333333333333}
{"id": "WebQTest-22", "prediction": ["# Reasoning Path:\nEgypt\n# Answer:\nEgypt"], "ground_truth": ["Provisional government", "Semi-presidential system"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-23", "prediction": ["# Reasoning Path:\nMartin Luther King, Jr.\n# Answer:\nMemphis", "# Reasoning Path:\nMartin Luther King, Jr. -> people.deceased_person.place_of_death -> Memphis -> location.location.events -> Assassination of Martin Luther King, Jr.\n# Answer:\nMemphis", "# Reasoning Path:\nMartin Luther King, Jr. -> people.deceased_person.place_of_death -> Memphis -> base.biblioness.bibs_location.country -> United States of America\n# Answer:\nMemphis"], "ground_truth": ["Memphis"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.8, "path_precision": 0.6666666666666666, "path_recall": 1.0, "path_ans_f1": 0.8, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 1.0}
{"id": "WebQTest-24", "prediction": ["# Reasoning Path:\nEdgar Allan Poe\n# Answer:\nBaltimore", "# Reasoning Path:\nEdgar Allan Poe -> people.deceased_person.place_of_death -> Baltimore -> travel.travel_destination.tourist_attractions -> Edgar Allan Poe House and Museum\n# Answer:\nBaltimore", "# Reasoning Path:\nEdgar Allan Poe -> people.deceased_person.place_of_burial -> Westminster Hall and Burying Ground\n# Answer:\nWestminster Hall and Burying Ground", "# Reasoning Path:\nEdgar Allan Poe -> people.deceased_person.place_of_death -> Baltimore -> location.administrative_division.second_level_division_of -> United States of America\n# Answer:\nBaltimore"], "ground_truth": ["Baltimore"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 0.8571428571428571, "ans_precission": 0.75, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-26", "prediction": ["# Reasoning Path:\nAtlanta\n# Answer:\nWorld of Coca-Cola", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> World of Coca-Cola -> common.topic.notable_types -> Museum\n# Answer:\nWorld of Coca-Cola", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> Zoo Atlanta -> zoos.zoo.exhibits -> The World of Reptiles\n# Answer:\nZoo Atlanta", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> World of Coca-Cola -> location.location.containedby -> Georgia\n# Answer:\nWorld of Coca-Cola", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> Zoo Atlanta -> zoos.zoo.exhibits -> The Orkin Children\u2019s Zoo\n# Answer:\nZoo Atlanta", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> Zoo Atlanta -> zoos.zoo.memberships -> World Association of Zoos and Aquariums\n# Answer:\nZoo Atlanta", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> Zoo Atlanta -> common.topic.notable_types -> Zoo\n# Answer:\nZoo Atlanta", "# Reasoning Path:\nAtlanta -> travel.travel_destination.tourist_attractions -> World of Coca-Cola -> location.location.containedby -> Fulton County\n# Answer:\nWorld of Coca-Cola"], "ground_truth": ["Centennial Olympic Park", "Georgia State Capitol", "Atlanta Jewish Film Festival", "Underground Atlanta", "Six Flags White Water", "Atlanta History Center", "Georgia Dome", "Four Seasons Hotel Atlanta", "Woodruff Arts Center", "Arbor Place Mall", "Martin Luther King, Jr. National Historic Site", "Atlanta Symphony Orchestra", "Georgia Aquarium", "Jimmy Carter Library and Museum", "Masquerade", "Atlanta Marriott Marquis", "Fox Theatre", "Atlanta Ballet", "Georgia World Congress Center", "Fernbank Science Center", "Philips Arena", "CNN Center", "Center for Puppetry Arts", "Fernbank Museum of Natural History", "Six Flags Over Georgia", "Zoo Atlanta", "Margaret Mitchell House & Museum", "Peachtree Road Race", "The Tabernacle", "Turner Field", "Hyatt Regency Atlanta", "Omni Coliseum", "Variety Playhouse", "Atlanta Cyclorama & Civil War Museum", "Cobb Energy Performing Arts Centre", "World of Coca-Cola"], "ans_acc": 0.05555555555555555, "ans_hit": 1, "ans_f1": 0.10526315789473684, "ans_precission": 1.0, "ans_recall": 0.05555555555555555, "path_f1": 0.10447761194029849, "path_precision": 0.875, "path_recall": 0.05555555555555555, "path_ans_f1": 0.10447761194029849, "path_ans_precision": 0.875, "path_ans_recall": 0.05555555555555555}
{"id": "WebQTest-28", "prediction": ["# Reasoning Path:\nAnna Bligh\n# Answer:\nAnna Bligh"], "ground_truth": ["Electoral district of South Brisbane"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-3", "prediction": ["# Reasoning Path:\nCoronation Street\n# Answer:\nCoronation Street"], "ground_truth": ["William Roache"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-31", "prediction": ["# Reasoning Path:\nAndy Murray\n# Answer:\nAndy Murray"], "ground_truth": ["2005"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-32", "prediction": ["# Reasoning Path:\nAustralian dollar\n# Answer:\nAustralian dollar"], "ground_truth": ["AUD"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-33", "prediction": ["# Reasoning Path:\nSweden\n# Answer:\nSweden"], "ground_truth": ["Central European Time Zone"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-34", "prediction": ["# Reasoning Path:\nCam Newton\n# Answer:\nCam Newton"], "ground_truth": ["Carolina Panthers"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-35", "prediction": ["# Reasoning Path:\nFrederick\n# Answer:\nFrederick County", "# Reasoning Path:\nFrederick -> location.hud_county_place.county -> Frederick County\n# Answer:\nFrederick County"], "ground_truth": ["Frederick County"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-36", "prediction": ["# Reasoning Path:\nHarper Lee\n# Answer:\nHarper Lee"], "ground_truth": ["Monroe County High School"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-37", "prediction": ["# Reasoning Path:\nUtah\n# Answer:\nUtah"], "ground_truth": ["Mountain Time Zone"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-38", "prediction": ["# Reasoning Path:\nGeorge W. Bush\n# Answer:\nGeorge W. Bush"], "ground_truth": ["Gene Amondson", "Michael Peroutka", "John Kerry", "Ralph Nader"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-39", "prediction": ["# Reasoning Path:\nNiall Ferguson\n# Answer:\nNiall Ferguson"], "ground_truth": ["Ayaan Hirsi Ali"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-41", "prediction": ["# Reasoning Path:\nGal\u00e1pagos Islands\n# Answer:\nEcuador", "# Reasoning Path:\nGal\u00e1pagos Islands -> location.location.containedby -> Ecuador -> location.country.administrative_divisions -> Gal\u00e1pagos Province\n# Answer:\nEcuador", "# Reasoning Path:\nGal\u00e1pagos Islands -> location.location.contains -> Santa Cruz Canton, Ecuador -> location.administrative_division.capital -> m.0pyz7gg\n# Answer:\nSanta Cruz Canton, Ecuador", "# Reasoning Path:\nGal\u00e1pagos Islands -> location.location.containedby -> Ecuador -> location.location.partially_contained_by -> m.0wg99t5\n# Answer:\nEcuador", "# Reasoning Path:\nGal\u00e1pagos Islands -> location.location.containedby -> Ecuador -> location.location.containedby -> Americas\n# Answer:\nEcuador", "# Reasoning Path:\nGal\u00e1pagos Islands -> location.location.contains -> Santa Cruz Canton, Ecuador -> location.location.geolocation -> m.0wmqhv9\n# Answer:\nSanta Cruz Canton, Ecuador"], "ground_truth": ["Ecuador", "Pacific Ocean", "Gal\u00e1pagos Province"], "ans_acc": 0.6666666666666666, "ans_hit": 1, "ans_f1": 0.5, "ans_precission": 1.0, "ans_recall": 0.3333333333333333, "path_f1": 0.4, "path_precision": 0.5, "path_recall": 0.3333333333333333, "path_ans_f1": 0.7407407407407408, "path_ans_precision": 0.8333333333333334, "path_ans_recall": 0.6666666666666666}
{"id": "WebQTest-42", "prediction": ["# Reasoning Path:\nJustin Bieber\n# Answer:\nJustin Bieber"], "ground_truth": ["As Long as You Love Me", "PYD", "Pray", "Home to Mama", "All Bad", "Bigger", "Never Let You Go", "Somebody to Love", "All Around The World", "Roller Coaster", "Eenie Meenie", "First Dance", "Wait for a Minute", "Never Say Never", "Right Here", "Confident", "Turn to You (Mother's Day Dedication)", "Die in Your Arms", "Beauty And A Beat", "#thatPower", "Bad Day", "Recovery", "Hold Tight", "Thought Of You", "Boyfriend", "Lolly", "Live My Life", "Heartbreaker", "Baby", "All That Matters", "Change Me"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-43", "prediction": ["# Reasoning Path:\nGeorges Cl\u00e9menceau\n# Answer:\nGeorges Cl\u00e9menceau"], "ground_truth": ["Statesman", "Physician", "Journalist", "Writer", "Publisher"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-44", "prediction": ["# Reasoning Path:\nArizona\n# Answer:\nArizona"], "ground_truth": ["Saguaro"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-45", "prediction": ["# Reasoning Path:\nRihanna\n# Answer:\nRihanna"], "ground_truth": ["Saint Michael Parish"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-46", "prediction": ["# Reasoning Path:\nWilliam Henry Harrison\n# Answer:\nWilliam Henry Harrison"], "ground_truth": ["1841-03-04"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-47", "prediction": ["# Reasoning Path:\nGeorge Lopez\n# Answer:\nGeorge Lopez"], "ground_truth": ["Mission Hills"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-48", "prediction": ["# Reasoning Path:\nSamsung Group\n# Answer:\nSamsung Group"], "ground_truth": ["Suwon"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-49", "prediction": ["# Reasoning Path:\nIslam\n# Answer:\nSunni Islam", "# Reasoning Path:\nIslam -> religion.religion.branched_into -> Sunni Islam -> religion.religion.texts -> Holy Quran\n# Answer:\nSunni Islam", "# Reasoning Path:\nIslam -> religion.religion.deities -> Allah -> religion.deity.deity_of -> Sunni Islam\n# Answer:\nAllah", "# Reasoning Path:\nIslam -> religion.religion.branched_into -> Sunni Islam -> religion.religion.deities -> Allah\n# Answer:\nSunni Islam", "# Reasoning Path:\nIslam -> religion.religion.deities -> Allah -> common.topic.article -> m.0jfq\n# Answer:\nAllah", "# Reasoning Path:\nIslam -> religion.religion.deities -> Allah -> common.topic.image -> Name of All\u0101h written in Arabic calligraphy by 17th century Ottoman artist H\u00e2f\u0131z Osman.\n# Answer:\nAllah"], "ground_truth": ["Entering Heaven alive", "Mahdi", "Sharia", "Monotheism", "Predestination in Islam", "Islamic holy books", "Qiyamah", "Islamic view of angels", "Tawhid", "Prophets in Islam", "Masih ad-Dajjal", "God in Islam", "\u1e6c\u016bb\u0101"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-51", "prediction": ["# Reasoning Path:\nChristian Grey\n# Answer:\nChristian Grey"], "ground_truth": ["Jamie Dornan"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-52", "prediction": ["# Reasoning Path:\nGeorge Orwell\n# Answer:\nGeorge Orwell"], "ground_truth": ["Tuberculosis"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-54", "prediction": ["# Reasoning Path:\nAdolf Hitler\n# Answer:\nGermany", "# Reasoning Path:\nAdolf Hitler -> people.person.nationality -> Germany\n# Answer:\nGermany"], "ground_truth": ["Nazi Germany"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-55", "prediction": ["# Reasoning Path:\nMichael Bubl\u00e9\n# Answer:\nMichael Bubl\u00e9"], "ground_truth": ["Singer", "Actor", "Songwriter"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-56", "prediction": ["# Reasoning Path:\nKansas City\n# Answer:\nWyandotte County", "# Reasoning Path:\nKansas Speedway\n# Answer:\nWyandotte County", "# Reasoning Path:\nKansas City -> location.hud_county_place.county -> Wyandotte County\n# Answer:\nWyandotte County", "# Reasoning Path:\nKansas Speedway -> location.location.containedby -> Wyandotte County\n# Answer:\nWyandotte County"], "ground_truth": ["Wyandotte County"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-58", "prediction": ["# Reasoning Path:\nJackie Robinson\n# Answer:\nJackie Robinson"], "ground_truth": ["UCLA Bruins football"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-59", "prediction": ["# Reasoning Path:\nAnnie\n# Answer:\nAnnie"], "ground_truth": ["1976-08-10"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0, "path_recall": 0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-6", "prediction": ["# Reasoning Path:\nJaMarcus Russell\n# Answer:\nJaMarcus Russell"], "ground_truth": ["Mobile"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-60", "prediction": ["# Reasoning Path:\nEleanor Roosevelt\n# Answer:\nEleanor Roosevelt"], "ground_truth": ["Manhattan"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-61", "prediction": ["# Reasoning Path:\nIndonesia\n# Answer:\nIndonesia"], "ground_truth": ["Hinduism", "Protestantism", "Catholicism", "Islam"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-62", "prediction": ["# Reasoning Path:\nJesse James\n# Answer:\nJesse James"], "ground_truth": ["Firearm"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-63", "prediction": ["# Reasoning Path:\nAbraham Lincoln\n# Answer:\nAndrew Johnson", "# Reasoning Path:\nAbraham Lincoln -> government.us_president.vice_president -> Andrew Johnson\n# Answer:\nAndrew Johnson", "# Reasoning Path:\nAbraham Lincoln -> government.us_president.vice_president -> Hannibal Hamlin\n# Answer:\nHannibal Hamlin"], "ground_truth": ["Hannibal Hamlin", "Andrew Johnson"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.8, "path_precision": 0.6666666666666666, "path_recall": 1.0, "path_ans_f1": 0.8, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 1.0}
{"id": "WebQTest-64", "prediction": ["# Reasoning Path:\nCharles Dickens\n# Answer:\nCharles Dickens"], "ground_truth": ["A Christmas Carol (Acting Edition)", "A Tale of Two Cities (Ladybird Children's Classics)", "A Christmas Carol (Soundings)", "A Tale of Two Cities (Penguin Readers, Level 5)", "A Christmas Carol (Everyman's Library Children's Classics)", "A Christmas Carol (Clear Print)", "The cricket on the hearth", "A Tale of Two Cities (Classics Illustrated Notes)", "A Tale of Two Cities (Acting Edition)", "Great expectations", "A Tale of Two Cities (Illustrated Junior Library)", "A Tale of Two Cities (Masterworks)", "A Tale of Two Cities (Everyman's Library Classics)", "A Tale of Two Cities (Bantam Classic)", "A Christmas Carol (Watermill Classics)", "Bleak House", "David Copperfield", "A Tale of Two Cities (Piccolo Books)", "A Tale of Two Cities (Barnes & Noble Classics Series)", "The Pickwick Papers", "A Tale of Two Cities (Adopted Classic)", "A Christmas Carol (Enriched Classics)", "A Christmas Carol (Pacemaker Classic)", "A Christmas Carol (Wordsworth Collection) (Wordsworth Collection)", "A Christmas Carol (Read & Listen Books)", "A CHRISTMAS CAROL", "A Christmas Carol (Illustrated Classics)", "A Tale of Two Cities (Progressive English)", "A Tale of Two Cities (Konemann Classics)", "A Tale of Two Cities (Naxos AudioBooks)", "A Christmas Carol (Take Part)", "A Tale of Two Cities (Clear Print)", "A Christmas Carol (Thornes Classic Novels)", "A Tale of Two Cities (Unabridged Classics)", "A Christmas Carol (Young Reading Series 2)", "A Tale of Two Cities (Webster's Chinese-Simplified Thesaurus Edition)", "A Christmas Carol (Children's Theatre Playscript)", "A Christmas Carol (Nelson Graded Readers)", "A Tale of Two Cities (Paperback Classics)", "A Tale of Two Cities (40th Anniversary Edition)", "Dombey and Son.", "A Christmas Carol (Puffin Classics)", "A Tale of Two Cities (Webster's Italian Thesaurus Edition)", "A Christmas Carol (Usborne Young Reading)", "A Tale of Two Cities (Illustrated Classics)", "Martin Chuzzlewit", "A Christmas Carol (Through the Magic Window Series)", "A Christmas Carol (Classic Fiction)", "A Tale of Two Cities (Puffin Classics)", "A Christmas Carol (Cp 1135)", "A Christmas Carol (Dramascripts)", "A Christmas Carol (Classics for Young Adults and Adults)", "A Christmas Carol (Scholastic Classics)", "A Christmas Carol (Large Print)", "A Christmas Carol (Webster's Korean Thesaurus Edition)", "A Tale of Two Cities (Prentice Hall Science)", "A Tale of Two Cities (Enriched Classic)", "A Tale of Two Cities (Classic Literature with Classical Music)", "A Tale of Two Cities (Bookcassette(r) Edition)", "A Tale of Two Cities (Wordsworth Classics)", "A Tale of Two Cities (Longman Fiction)", "Great Expectations.", "A Christmas Carol (Gollancz Children's Classics)", "A Tale of Two Cities (Cassette (1 Hr).)", "Bleak House.", "A Christmas Carol (Limited Editions)", "A Christmas Carol (Penguin Readers, Level 2)", "A Tale of Two Cities (Pacemaker Classics)", "A Christmas Carol (Classics Illustrated)", "A Tale of Two Cities (The Greatest Historical Novels)", "A Tale of Two Cities (Webster's Portuguese Thesaurus Edition)", "A Christmas Carol (Tor Classics)", "A Tale of Two Cities", "A Christmas Carol (Dramascripts Classic Texts)", "A Tale of Two Cities (Isis Clear Type Classic)", "The old curiosity shop.", "Dombey and son", "A Tale of Two Cities (Signet Classics)", "A Christmas Carol (Great Stories)", "A Tale of Two Cities (Cyber Classics)", "A Tale of Two Cities (Webster's German Thesaurus Edition)", "A Christmas Carol (Whole Story)", "A Tale of Two Cities (Dodo Press)", "A TALE OF TWO CITIES", "A Christmas Carol (New Longman Literature)", "The life and adventures of Nicholas Nickleby", "A Tale of Two Cities (Classics Illustrated)", "The Old Curiosity Shop", "A Christmas Carol (The Kennett Library)", "Sketches by Boz", "A Tale of Two Cities (Dramascripts S.)", "A Christmas Carol (Cover to Cover)", "A Christmas Carol", "A Tale Of Two Cities (Adult Classics in Audio)", "The Pickwick papers", "Little Dorrit", "The mystery of Edwin Drood", "A Tale of Two Cities (Lake Illustrated Classics, Collection 2)", "A Christmas Carol (Classic, Picture, Ladybird)", "A Tale of Two Cities (Amsco Literature Program - N 380 ALS)", "A Tale of Two Cities (Tor Classics)", "A Tale of Two Cities (Collected Works of Charles Dickens)", "A Christmas Carol (Children's Classics)", "A Christmas Carol. (Lernmaterialien)", "A Christmas Carol (Penguin Student Editions)", "A Christmas Carol (Illustrated Classics (Graphic Novels))", "A Tale of Two Cities (Simple English)", "A Tale of Two Cities (Everyman Paperbacks)", "A Tale of Two Cities (Longman Classics, Stage 2)", "A Tale of Two Cities (Oxford Bookworms Library)", "A Tale of Two Cities (Student's Novels)", "A Christmas Carol (Chrysalis Children's Classics Series)", "A Tale of Two Cities (Saddleback Classics)", "A Tale of Two Cities (Soundings)", "A Tale of Two Cities (Silver Classics)", "A Christmas Carol (Value Books)", "A Tale of Two Cities (BBC Audio Series)", "A Tale of Two Cities (10 Cassettes)", "A Christmas Carol (R)", "A Tale of Two Cities (Dramatized)", "A Tale of Two Cities (Unabridged Classics for High School and Adults)", "A Christmas Carol (Radio Theatre)", "David Copperfield.", "A Christmas Carol (Classic Collection)", "A Tale of Two Cities (Classic Fiction)", "Oliver Twist", "Great Expectations", "A Christmas Carol (Aladdin Classics)", "A Tale of Two Cities (Oxford Playscripts)", "A Tale of Two Cities (Large Print Edition)", "Hard times", "A Tale of Two Cities (Compact English Classics)", "Dombey and Son", "A Christmas Carol (Apple Classics)", "Our mutual friend", "A Tale of Two Cities (The Classic Collection)", "The old curiosity shop", "A Christmas Carol (Ladybird Classics)", "A Tale Of Two Cities (Adult Classics)", "A Christmas Carol (Saddleback Classics)", "A Tale of Two Cities (Classic Retelling)", "A Christmas Carol (Audio Editions)", "A Tale of Two Cities (Macmillan Students' Novels)", "A Tale Of Two Cities (Classic Books on Cassettes Collection)", "A Christmas Carol (Oxford Bookworms Library)", "A Tale of Two Cities (Cover to Cover Classics)", "Our mutual friend.", "A Christmas Carol (Ladybird Children's Classics)", "Bleak house", "Great expectations.", "A Tale of Two Cities (Ultimate Classics)", "A Christmas Carol (Classic Books on Cassettes Collection)", "A Tale of Two Cities (Collector's Library)", "A Christmas Carol (Watermill Classic)", "A Christmas Carol (Bantam Classic)", "A Christmas Carol (Reissue)", "A Tale of Two Cities (Penguin Classics)", "A Tale of Two Cities (Penguin Popular Classics)", "A Christmas Carol (Pacemaker Classics)", "A Tale of Two Cities (Courage Literary Classics)", "A Christmas Carol (Green Integer, 50)", "A Tale of Two Cities (Dover Thrift Editions)", "A Christmas Carol (Family Classics)", "A Tale of Two Cities (Everyman's Library (Paper))", "A Christmas Carol (Puffin Choice)", "The Mystery of Edwin Drood", "A Christmas Carol (Webster's Portuguese Thesaurus Edition)", "A Tale of Two Cities (Webster's Chinese-Traditional Thesaurus Edition)", "A Tale of Two Cities (New Oxford Illustrated Dickens)"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-65", "prediction": ["# Reasoning Path:\nSoviet Union\n# Answer:\nSoviet Union"], "ground_truth": ["Vladimir Lenin"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-66", "prediction": ["# Reasoning Path:\nPuerto Rico\n# Answer:\nUnited States Dollar", "# Reasoning Path:\nPuerto Rico -> location.country.currency_used -> United States Dollar\n# Answer:\nUnited States Dollar"], "ground_truth": ["United States Dollar"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-67", "prediction": ["# Reasoning Path:\nCarl Wilson -> people.deceased_person.cause_of_death -> Brain tumor\n# Answer:\nBrain tumor", "# Reasoning Path:\nCarl Wilson -> people.deceased_person.cause_of_death -> Lung cancer\n# Answer:\nLung cancer", "# Reasoning Path:\nCarl Wilson\n# Answer:\nBrain tumor"], "ground_truth": ["Lung cancer", "Brain tumor"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.8, "path_precision": 0.6666666666666666, "path_recall": 1.0, "path_ans_f1": 0.8, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 1.0}
{"id": "WebQTest-68", "prediction": ["# Reasoning Path:\nKnight Rider\n# Answer:\nKnight Rider"], "ground_truth": ["William Daniels"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-69", "prediction": ["# Reasoning Path:\nBrentwood\n# Answer:\nWilliamson County", "# Reasoning Path:\nBrentwood -> location.hud_county_place.county -> Williamson County -> location.administrative_division.second_level_division_of -> United States of America\n# Answer:\nWilliamson County", "# Reasoning Path:\nBrentwood -> location.hud_county_place.county -> Williamson County -> location.statistical_region.co2_emissions_industrial -> m.045km10\n# Answer:\nWilliamson County", "# Reasoning Path:\nBrentwood -> location.hud_county_place.county -> Williamson County -> location.statistical_region.co2_emissions_residential -> m.045j_kp\n# Answer:\nWilliamson County"], "ground_truth": ["Williamson County"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0.8571428571428571, "path_ans_precision": 0.75, "path_ans_recall": 1.0}
{"id": "WebQTest-7", "prediction": ["# Reasoning Path:\nGeorge Washington Carver\n# Answer:\nGeorge Washington Carver"], "ground_truth": ["Diamond"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-71", "prediction": ["# Reasoning Path:\nMichael J. Fox\n# Answer:\nMichael J. Fox"], "ground_truth": ["Tracy Pollan"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-72", "prediction": ["# Reasoning Path:\nStonewall Jackson\n# Answer:\nAmerican Civil War", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> American Civil War -> military.military_conflict.combatants -> m.03z965k\n# Answer:\nAmerican Civil War", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> American Civil War -> military.military_conflict.combatants -> m.03z98d_\n# Answer:\nAmerican Civil War", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> American Civil War -> military.military_conflict.commanders -> m.0bmz024\n# Answer:\nAmerican Civil War", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> Battle of Chancellorsville -> military.military_conflict.commanders -> m.049y352\n# Answer:\nBattle of Chancellorsville", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> American Civil War -> military.military_conflict.commanders -> m.0bm_34q\n# Answer:\nAmerican Civil War", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> Battle of Chancellorsville -> military.military_conflict.commanders -> m.049y34n\n# Answer:\nBattle of Chancellorsville", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> Battle of Chancellorsville -> military.military_conflict.combatants -> m.04fvggl\n# Answer:\nBattle of Chancellorsville", "# Reasoning Path:\nStonewall Jackson -> military.military_person.participated_in_conflicts -> American Civil War -> military.military_conflict.commanders -> m.0bm_54t\n# Answer:\nAmerican Civil War"], "ground_truth": ["American Civil War", "Battle of Hoke's Run", "First Battle of Winchester", "Battle of Port Republic", "Battle of Front Royal", "First Battle of Rappahannock Station", "Jackson's Valley Campaign", "Battle of Hancock", "Second Battle of Bull Run", "Battle of Harpers Ferry", "Battle of Chantilly", "Battle of White Oak Swamp", "Manassas Station Operations", "Romney Expedition", "How Few Remain", "Battle of McDowell", "Battle of Cedar Mountain", "First Battle of Kernstown", "Battle of Chancellorsville"], "ans_acc": 0.10526315789473684, "ans_hit": 1, "ans_f1": 0.1904761904761905, "ans_precission": 1.0, "ans_recall": 0.10526315789473684, "path_f1": 0.13675213675213674, "path_precision": 0.8888888888888888, "path_recall": 0.07407407407407407, "path_ans_f1": 0.18823529411764706, "path_ans_precision": 0.8888888888888888, "path_ans_recall": 0.10526315789473684}
{"id": "WebQTest-73", "prediction": ["# Reasoning Path:\nMaasai people\n# Answer:\nMaasai people"], "ground_truth": ["Maasai Language"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-74", "prediction": ["# Reasoning Path:\nBenjamin Franklin\n# Answer:\nBenjamin Franklin"], "ground_truth": ["Deborah Read"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-75", "prediction": ["# Reasoning Path:\nPatrick Swayze\n# Answer:\nPancreatic cancer", "# Reasoning Path:\nPatrick Swayze -> people.deceased_person.cause_of_death -> Pancreatic cancer\n# Answer:\nPancreatic cancer", "# Reasoning Path:\nPatrick Swayze -> medicine.notable_person_with_medical_condition.condition -> Pancreatic cancer\n# Answer:\nPancreatic cancer"], "ground_truth": ["Pancreatic cancer"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.5, "path_precision": 0.3333333333333333, "path_recall": 1.0, "path_ans_f1": 0.8, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 1.0}
{"id": "WebQTest-76", "prediction": ["# Reasoning Path:\nLeonardo da Vinci\n# Answer:\nThe Last Supper", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Last Supper -> visual_art.artwork.art_subject -> Jesus Christ\n# Answer:\nThe Last Supper", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Last Supper -> visual_art.artwork.art_form -> Painting\n# Answer:\nThe Last Supper", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Virgin and Child with St Anne and St John the Baptist -> visual_art.artwork.art_subject -> John the Baptist\n# Answer:\nThe Virgin and Child with St Anne and St John the Baptist", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Last Supper -> visual_art.artwork.art_genre -> Christian art\n# Answer:\nThe Last Supper", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Virgin and Child with St Anne and St John the Baptist -> visual_art.artwork.art_subject -> Mary\n# Answer:\nThe Virgin and Child with St Anne and St John the Baptist", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Last Supper -> visual_art.artwork.art_genre -> History painting\n# Answer:\nThe Last Supper", "# Reasoning Path:\nLeonardo da Vinci -> visual_art.visual_artist.artworks -> The Virgin and Child with St Anne and St John the Baptist -> visual_art.artwork.art_subject -> Jesus Christ\n# Answer:\nThe Virgin and Child with St Anne and St John the Baptist"], "ground_truth": ["Lady with an Ermine", "The Last Supper", "The Baptism of Christ", "The Virgin and Child with St Anne and St John the Baptist", "Head of a Woman", "Bacchus", "Madonna of the Carnation", "St. Jerome in the Wilderness", "St. John the Baptist", "g.120vt1gz", "Horse and Rider", "g.1213jb_b", "Benois Madonna", "Madonna Litta", "Virgin of the Rocks", "Madonna and Child with St Joseph", "Madonna of Laroque", "g.1239jd9p", "Madonna of the Yarnwinder", "Mona Lisa", "Portrait of a Young Fianc\u00e9e", "Portrait of Isabella d'Este", "Sala delle Asse", "The Holy Infants Embracing", "Annunciation", "Salvator Mundi", "La belle ferronni\u00e8re", "Leonardo's horse", "Portrait of a man in red chalk", "Adoration of the Magi", "The Virgin and Child with St. Anne", "Portrait of a Musician", "g.1219sb0g", "Medusa", "g.121yh91r", "g.12314dm1", "g.1224tf0c", "g.12215rxg", "The Battle of Anghiari", "Ginevra de' Benci", "Leda and the Swan", "Vitruvian Man", "Drapery for a Seated Figure", "Lucan portrait of Leonardo da Vinci", "g.121wt37c"], "ans_acc": 0.08888888888888889, "ans_hit": 1, "ans_f1": 0.163265306122449, "ans_precission": 1.0, "ans_recall": 0.08888888888888889, "path_f1": 0.12650602409638553, "path_precision": 0.875, "path_recall": 0.06818181818181818, "path_ans_f1": 0.16138328530259366, "path_ans_precision": 0.875, "path_ans_recall": 0.08888888888888889}
{"id": "WebQTest-77", "prediction": ["# Reasoning Path:\nAustria\n# Answer:\nVienna", "# Reasoning Path:\nAustria -> location.country.capital -> Vienna\n# Answer:\nVienna"], "ground_truth": ["Vienna"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-78", "prediction": ["# Reasoning Path:\nEva Per\u00f3n\n# Answer:\nCervical cancer", "# Reasoning Path:\nEva Per\u00f3n -> people.deceased_person.cause_of_death -> Cervical cancer\n# Answer:\nCervical cancer"], "ground_truth": ["Cervical cancer"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-79", "prediction": ["# Reasoning Path:\nGautama Buddha\n# Answer:\nNepal", "# Reasoning Path:\nGautama Buddha -> people.person.nationality -> Nepal\n# Answer:\nNepal"], "ground_truth": ["Nepal"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-8", "prediction": ["# Reasoning Path:\nBenjamin Franklin\n# Answer:\nBenjamin Franklin"], "ground_truth": ["Bifocals", "Franklin stove", "Lightning rod", "Glass harmonica"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-80", "prediction": ["# Reasoning Path:\nGreeley -> location.hud_county_place.county -> Weld County\n# Answer:\nWeld County", "# Reasoning Path:\nGreeley\n# Answer:\nWeld County"], "ground_truth": ["Weld County"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-82", "prediction": ["# Reasoning Path:\nPyotr Ilyich Tchaikovsky\n# Answer:\nPyotr Ilyich Tchaikovsky"], "ground_truth": ["Musician", "Librettist", "Composer"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-83", "prediction": ["# Reasoning Path:\nGerman Language\n# Answer:\nGerman Language"], "ground_truth": ["Austria", "East Germany", "Liechtenstein", "Germany", "Belgium", "Switzerland", "Luxembourg"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-84", "prediction": ["# Reasoning Path:\nJohn Lennon\n# Answer:\nPsychedelic rock", "# Reasoning Path:\nJohn Lennon -> music.artist.genre -> Psychedelic rock\n# Answer:\nPsychedelic rock", "# Reasoning Path:\nJohn Lennon -> music.artist.genre -> Rock music\n# Answer:\nRock music", "# Reasoning Path:\nJohn Lennon -> music.artist.genre -> Pop rock\n# Answer:\nPop rock"], "ground_truth": ["Pop music", "Soft rock", "Rock music", "Experimental rock", "Psychedelic rock", "Blues rock", "Experimental music", "Art rock", "Pop rock"], "ans_acc": 0.3333333333333333, "ans_hit": 1, "ans_f1": 0.5, "ans_precission": 1.0, "ans_recall": 0.3333333333333333, "path_f1": 0.46153846153846156, "path_precision": 0.75, "path_recall": 0.3333333333333333, "path_ans_f1": 0.46153846153846156, "path_ans_precision": 0.75, "path_ans_recall": 0.3333333333333333}
{"id": "WebQTest-85", "prediction": ["# Reasoning Path:\nColorado\n# Answer:\nColorado"], "ground_truth": ["Michael Bennet", "Mark Udall"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-86", "prediction": ["# Reasoning Path:\nGreenland\n# Answer:\nDenmark", "# Reasoning Path:\nGreenland -> location.administrative_division.country -> Denmark\n# Answer:\nDenmark"], "ground_truth": ["Denmark"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-87", "prediction": ["# Reasoning Path:\nSeattle\n# Answer:\n98101", "# Reasoning Path:\nSeattle -> location.citytown.postal_codes -> 98101\n# Answer:\n98101"], "ground_truth": ["98171", "98116", "98199", "98129", "98170", "98145", "98146", "98161", "98188", "98164", "98119-4114", "98138", "98136", "98158", "98154", "98127", "98131", "98132", "98175", "98117", "98155", "98165", "98134", "98106", "98105", "98133", "98191", "98113", "98141", "98181", "98109", "98190", "98108", "98168", "98114", "98185", "98178", "98122", "98121", "98148", "98139", "98119", "98125", "98160", "98184", "98144", "98115", "98124", "98166", "98198", "98102", "98107", "98101", "98174", "98177", "98118", "98103", "98112", "98194", "98111", "98126", "98195", "98104"], "ans_acc": 0.015873015873015872, "ans_hit": 1, "ans_f1": 0.03125, "ans_precission": 1.0, "ans_recall": 0.015873015873015872, "path_f1": 0.03076923076923077, "path_precision": 0.5, "path_recall": 0.015873015873015872, "path_ans_f1": 0.03076923076923077, "path_ans_precision": 0.5, "path_ans_recall": 0.015873015873015872}
{"id": "WebQTest-88", "prediction": ["# Reasoning Path:\nWillow Smith\n# Answer:\nJada Pinkett Smith", "# Reasoning Path:\nWillow Smith -> people.person.parents -> Jada Pinkett Smith\n# Answer:\nJada Pinkett Smith"], "ground_truth": ["Jada Pinkett Smith"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-89", "prediction": ["# Reasoning Path:\nChinese language\n# Answer:\nChinese characters", "# Reasoning Path:\nChinese language -> language.human_language.writing_system -> Chinese characters\n# Answer:\nChinese characters", "# Reasoning Path:\nChinese language -> language.human_language.writing_system -> Traditional Chinese characters\n# Answer:\nTraditional Chinese characters"], "ground_truth": ["N\u00fcshu script", "Simplified Chinese character", "'Phags-pa script", "Traditional Chinese characters", "Chinese characters"], "ans_acc": 0.4, "ans_hit": 1, "ans_f1": 0.5714285714285715, "ans_precission": 1.0, "ans_recall": 0.4, "path_f1": 0.5, "path_precision": 0.6666666666666666, "path_recall": 0.4, "path_ans_f1": 0.5, "path_ans_precision": 0.6666666666666666, "path_ans_recall": 0.4}
{"id": "WebQTest-9", "prediction": ["# Reasoning Path:\nRichard Nixon\n# Answer:\nRichard Nixon"], "ground_truth": ["Pat Nixon"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-90", "prediction": ["# Reasoning Path:\nThe Jeffersons\n# Answer:\nThe Jeffersons"], "ground_truth": ["Roxie Roker", "Damon Evans", "Sherman Hemsley", "Marla Gibbs", "Zara Cully", "Paul Benedict", "Jay Hammer", "Berlinda Tolbert", "Isabel Sanford", "Franklin Cover", "Mike Evans"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-91", "prediction": ["# Reasoning Path:\nSan Francisco\n# Answer:\nSan Francisco Chronicle", "# Reasoning Path:\nSan Francisco -> periodicals.newspaper_circulation_area.newspapers -> San Francisco Chronicle\n# Answer:\nSan Francisco Chronicle", "# Reasoning Path:\nSan Francisco -> periodicals.newspaper_circulation_area.newspapers -> AsianWeek\n# Answer:\nAsianWeek", "# Reasoning Path:\nSan Francisco -> periodicals.newspaper_circulation_area.newspapers -> Bay Area Reporter -> common.topic.notable_types -> Newspaper\n# Answer:\nBay Area Reporter", "# Reasoning Path:\nSan Francisco -> periodicals.newspaper_circulation_area.newspapers -> Bay Area Reporter -> book.periodical.language -> English Language\n# Answer:\nBay Area Reporter"], "ground_truth": ["San Francisco Bay Times", "Synapse", "San Francisco Daily", "The San Francisco Examiner", "AsianWeek", "Street Sheet", "Bay Area Reporter", "San Francisco Bay Guardian", "San Francisco Chronicle", "The Daily Alta California", "The Golden Era", "San Francisco News-Call Bulletin Newspaper", "Free Society", "San Francisco Business Times", "San Francisco Call", "San Francisco Foghorn", "Dock of the Bay", "San Francisco Bay View", "California Star", "Sing Tao Daily"], "ans_acc": 0.15, "ans_hit": 1, "ans_f1": 0.2608695652173913, "ans_precission": 1.0, "ans_recall": 0.15, "path_f1": 0.2526315789473684, "path_precision": 0.8, "path_recall": 0.15, "path_ans_f1": 0.2526315789473684, "path_ans_precision": 0.8, "path_ans_recall": 0.15}
{"id": "WebQTest-93", "prediction": ["# Reasoning Path:\nArmenia\n# Answer:\nEurope", "# Reasoning Path:\nArmenia -> base.locations.countries.continent -> Europe\n# Answer:\nEurope"], "ground_truth": ["Europe"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-94", "prediction": ["# Reasoning Path:\nRandy Savage\n# Answer:\nheart attack", "# Reasoning Path:\nRandy Savage -> people.deceased_person.cause_of_death -> heart attack\n# Answer:\nheart attack"], "ground_truth": ["heart attack"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
{"id": "WebQTest-95", "prediction": ["# Reasoning Path:\nCharles Darwin\n# Answer:\nCharles Darwin"], "ground_truth": ["Journal of researches into the natural history and geology of the countries visited during the voyage round the world of the H. M. S. 'Beagle' under the command of Captain Fitz Roy, R. N", "The Correspondence of Charles Darwin, Volume 14: 1866", "Evolution", "The Different Forms of Flowers on Plants of the Same Species", "On a remarkable bar of sandstone off Pernambuco", "Darwin", "Der Ausdruck der Gem\u00fcthsbewegungen bei dem Menschen und den Thieren", "The Correspondence of Charles Darwin, Volume 13: 1865", "Die geschlechtliche Zuchtwahl", "Evolutionary Writings: Including the Autobiographies", "Letters from C. Darwin, Esq., to A. Hancock, Esq", "Charles Darwin's zoology notes & specimen lists from H.M.S. Beagle", "ontstaan der soorten door natuurlijke teeltkeus", "Geology from A Manual of scientific enquiry; prepared for the use of Her Majesty's Navy: and adapted for travellers in general", "Het uitdrukken van emoties bij mens en dier", "The\u0301orie de l'e\u0301volution", "Darwin-Wallace", "Charles Darwin, 1809-1882--Anton Dohrn, 1840-1909", "The collected papers of Charles Darwin", "A Monograph of the Sub-class Cirripedia, with Figures of all the Species. The Balanidae (or Sessile Cirripedes); the Verrucidae, etc.", "The Correspondence of Charles Darwin, Volume 9: 1861", "Geological Observations on the Volcanic Islands", "Motsa ha-minim", "Notes on the fertilization of orchids", "The Autobiography of Charles Darwin", "Darwin from Insectivorous Plants to Worms", "Les moyens d'expression chez les animaux", "The Essential Darwin", "Wu zhong qi yuan", "The education of Darwin", "Proiskhozhdenie vidov", "The Correspondence of Charles Darwin, Volume 17: 1869", "Das Variiren der Thiere und Pflanzen im Zustande der Domestication", "The living thoughts of Darwin", "Charles Darwin's letters", "The Power of Movement in Plants", "Geological Observations on South America", "The Correspondence of Charles Darwin, Volume 15: 1867", "On Natural Selection", "Volcanic Islands", "The Structure and Distribution of Coral Reefs", "Gesammelte kleinere Schriften", "Diario del Viaje de Un Naturalista Alrededor", "The Correspondence of Charles Darwin, Volume 3: 1844-1846", "The Darwin Reader Second Edition", "The action of carbonate of ammonia on the roots of certain plants", "Evolution and natural selection", "\u00dcber die Wege der Hummel-M\u00e4nnchen", "Reise um die Welt 1831 - 36", "From Darwin's unpublished notebooks", "genese\u014ds t\u014dn eid\u014dn", "Un m\u00e9moire in\u00e9dit de Charles Darwin sur l'instinct", "The Correspondence of Charles Darwin, Volume 18: 1870", "Die Bewegungen und Lebensweise der kletternden Pflanzen", "Notebooks on transmutation of species", "Darwin's notebooks on transmutation of species", "Beagle letters", "The Correspondence of Charles Darwin, Volume 12: 1864", "The Life of Erasmus Darwin", "Die Entstehung der Arten durch nat\u00fcrliche Zuchtwahl", "Memorias y epistolario i\u0301ntimo", "Del Plata a Tierra del Fuego", "El Origin De Las Especies", "On the tendency of species to form varieties", "The portable Darwin", "Monographs of the fossil Lepadidae and the fossil Balanidae", "\u00dcber den Bau und die Verbreitung der Corallen-Riffe", "Darwin's insects", "Charles Darwin's natural selection", "Works", "Fertilisation of Orchids", "The Correspondence of Charles Darwin, Volume 16: 1868", "The Correspondence of Charles Darwin, Volume 10: 1862", "vari\u00eberen der huisdieren en cultuurplanten", "The Effects of Cross and Self Fertilisation in the Vegetable Kingdom", "The Life and Letters of Charles Darwin Volume 1", "To the members of the Down Friendly Club", "Insectivorous Plants", "Voyage d'un naturaliste autour du monde", "La facult\u00e9 motrice dans les plantes", "The Formation of Vegetable Mould through the Action of Worms", "The Correspondence of Charles Darwin, Volume 7: 1858-1859", "The Correspondence of Charles Darwin, Volume 1: 1821-1836", "Darwin Darwin", "Darwin on humus and the earthworm", "A student's introduction to Charles Darwin", "A Monograph on the Fossil Balanid\u00e6 and Verrucid\u00e6 of Great Britain", "South American Geology", "The Life and Letters of Charles Darwin Volume 2", "The principal works", "Questions about the breeding of animals", "Darwinism stated by Darwin himself", "Die fundamente zur entstehung der arten", "The Orgin of Species", "The Variation of Animals and Plants under Domestication", "H.M.S. Beagle in South America", "The Correspondence of Charles Darwin, Volume 11: 1863", "A Monograph of the Sub-class Cirripedia, with Figures of all the Species. The Lepadidae; or, Pedunculated Cirripedes.", "Origins", "Darwin for Today", "Part I: Contributions to the Theory of Natural Selection / Part II", "Tesakneri tsagume\u030c", "La vie et la correspondance de Charles Darwin", "Rejse om jorden", "Kleinere geologische Abhandlungen", "On the Movements and Habits of Climbing Plants", "Reise eines Naturforschers um die Welt", "Evolution by natural selection", "The Correspondence of Charles Darwin, Volume 5: 1851-1855", "Die Wirkungen der Kreuz- und Selbst-Befruchtung im Pflanzenreich", "Opsht\u0323amung fun menshen", "Charles Darwin on the routes of male humble bees", "Darwin's journal", "The Voyage of the Beagle", "The Correspondence of Charles Darwin, Volume 4: 1847-1850", "The Descent of Man, and Selection in Relation to Sex", "The foundations of the Origin of species", "Metaphysics, Materialism, & the evolution of mind", "Charles Darwin", "The Expression of the Emotions in Man and Animals", "monograph on the sub-class Cirripedia", "Les mouvements et les habitudes des plantes grimpantes", "La descendance de l'homme et la s\u00a9\u00d8election sexuelle", "The Correspondence of Charles Darwin, Volume 2: 1837-1843", "Die verschiedenen Bl\u00fctenformen an Pflanzen der n\u00e4mlichen Art", "A Monograph on the Fossil Lepadidae, or, Pedunculated Cirripedes of Great Britain", "Darwin en Patagonia", "Geological observations on the volcanic islands and parts of South America visited during the voyage of H.M.S. 'Beagle", "Darwin and Henslow", "Leben und Briefe von Charles Darwin", "On evolution", "The geology of the voyage of H.M.S. Beagle", "The voyage of Charles Darwin", "Viaje de Un Naturalista Alrededor del Mundo 2 Vol", "The Darwin Reader First Edition", "Vospominanii\ufe20a\ufe21 o razvitii moego uma i kharaktera", "Cartas de Darwin 18251859", "The Correspondence of Charles Darwin, Volume 8: 1860", "Human nature, Darwin's view", "red notebook of Charles Darwin", "Seul celui qui change reste fid\u00e8le \u00e0 lui-m\u00eame", "From so simple a beginning", "More Letters of Charles Darwin", "On the origin of species by means of natural selection", "Les r\u00e9cifs de corail, leur structure et leur distribution", "Darwin's Ornithological notes", "A Darwin Selection", "Darwin Compendium", "Charles Darwin's marginalia", "The Correspondence of Charles Darwin, Volume 6: 1856-1857", "Resa kring jorden", "Diary of the voyage of H.M.S. Beagle", "The zoology of the voyage of H.M.S. Beagle during the years 1832-1836"], "ans_acc": 0.013071895424836602, "ans_hit": 1, "ans_f1": 0.02580645161290323, "ans_precission": 1.0, "ans_recall": 0.013071895424836602, "path_f1": 0.07142857142857142, "path_precision": 1.0, "path_recall": 0.037037037037037035, "path_ans_f1": 0.02580645161290323, "path_ans_precision": 1.0, "path_ans_recall": 0.013071895424836602}
{"id": "WebQTest-96", "prediction": ["# Reasoning Path:\nRichard Nixon\n# Answer:\nRichard Nixon"], "ground_truth": ["New York City"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-97", "prediction": ["# Reasoning Path:\nSmokey Robinson\n# Answer:\nSmokey Robinson"], "ground_truth": ["Just Like You", "My Guy", "You're Just My Life (feat. India.Arie)", "Aqui Contigo (Being With You) (Eric Bodi Rivera Mix)", "The Tears Of A Clown", "That Place", "Don't Wanna Be Just Physical", "God Rest Ye Merry Gentlemen", "Tell Me Tomorrow, Part 1", "Being With You", "I Have Prayed On It", "Theme From the Big Time", "And I Love Her", "Tell Me Tomorrow (12\\\" extended mix)", "Don't Play Another Love Song", "We've Saved the Best for Last", "Come to Me Soon", "You Go to My Head", "I\u2019ve Got You Under My Skin", "Virgin Man", "A Tattoo", "I Hear The Children Singing", "The Christmas Song (Chestnuts Roasting on an Open Fire) (feat. The Temptations)", "Quiet Storm (Groove Boutique remix)", "Be Careful What You Wish For (instrumental)", "You Take Me Away", "Because of You It's the Best It's Ever Been", "Cruisin", "Gone Forever", "It's Her Turn to Live", "I Can't Give You Anything but Love", "Blame It on Love", "The Love Between Me and My Kids", "Baby Come Close", "No Time to Stop Believing", "Quiet Storm", "My World", "Cruisin'", "Just Another Kiss", "Santa Claus is Coming to Town", "I've Made Love To You A Thousand Times", "I'm Glad There Is You", "Tears Of A Clown", "Why Do Happy Memories Hurt So Bad", "You Really Got a Hold on Me", "Close Encounters of the First Kind", "I Second That Emotions", "Whole Lot of Shakin\u2019 in My Heart (Since I Met You)", "Ever Had A Dream", "A Child Is Waiting", "We Are The Warriors", "Gang Bangin'", "It's Fantastic", "Skid Row", "Everything You Touch", "Girlfriend", "The Road to Damascus", "Bad Girl", "The Tracks of My Tears", "Share It", "Sweet Harmony", "Rewind", "Ooo Baby Baby", "Hold on to Your Love", "Will You Love Me Tomorrow", "Pops, We Love You (disco)", "I Can't Find", "Fulfill Your Need", "Please Come Home for Christmas", "Coincidentally", "Time Flies", "I've Made Love to You a Thousand Times", "Daylight & Darkness", "Why Are You Running From My Love", "Be Careful What You Wish For", "Vitamin U", "With Your Love Came", "As You Do", "Shoe Soul", "Let Me Be the Clock", "No\u00ebl", "Love Don' Give No Reason (12 Inch Club Mix)", "Just Passing Through", "You Are Forever", "Ooo Baby Baby (live)", "Jesus Told Me To Love You", "We've Saved The Best For Last (Kenny G with Smokey Robinson)", "If You Want My Love", "I'm in the Mood for Love", "If You Wanna Make Love", "Just to See Her", "You Made Me Feel Love", "I Care About Detroit", "It's a Good Feeling", "Love Brought Us Here", "If You Can Want", "Happy (Love Theme From Lady Sings the Blues)", "You Cannot Laugh Alone", "Will You Still Love Me Tomorrow", "Photograph in My Mind", "I've Got You Under My Skin", "Everything for Christmas", "Fallin'", "When Smokey Sings Tears Of A Clown", "It's Time to Stop Shoppin' Around", "Who's Sad", "The Track of My Tears", "You're the One for Me (feat. Joss Stone)", "What's Too Much", "I Second That Emotion", "Season's Greetings from Smokey Robinson", "Really Gonna Miss You", "Mother's Son", "Shop Around", "Yes It's You Lady", "The Tears of a Clown", "The Hurt's On You", "Be Kind To The Growing Mind (with The Temptations)", "Wedding Song", "Tea for Two", "I Am, I Am", "Walk on By", "Rack Me Back", "When A Woman Cries", "Little Girl Little Girl", "Don't Know Why", "Going to a Go Go", "Driving Thru Life in the Fast Lane", "Please Don't Take Your Love (feat. Carlos Santana)", "You've Really Go a Hold on Me", "I Am I Am", "Tell Me Tomorrow", "Fly Me to the Moon (In Other Words)", "He Can Fix Anything", "Keep Me", "The Christmas Song", "There Will Come a Day (I'm Gonna Happen to You)", "Jasmin", "I Can't Get Enough", "If You Wanna Make Love (Come 'round Here)", "Christmas Every Day", "I Love Your Face", "Just My Soul Responding", "Ooh Baby Baby", "Get Ready", "The Tracks of My Heart", "Quiet Storm (Groove Boutique Chill Jazz mix)", "Pops, We Love You", "Take Me Through The Night", "I Know You by Heart", "The Family Song", "Ebony Eyes (Duet with Rick James)", "Quiet Storm (Groove Boutique Chill Jazz mix feat. Ray Ayers)", "The Agony And The Ecstasy", "Going to a Gogo", "Aqui Con Tigo (Being With You)", "Speak Low", "There Will Come A Day ( I'm Gonna Happen To You )", "I Like Your Face", "Satisfy You", "Crusin", "Never My Love / Never Can Say Goodbye", "Tracks of my Tears", "Blame It On Love (Duet with Barbara Mitchell)", "Love' n Life", "And I Don't Love You (Larry Levan instrumental dub)", "Christmas Everyday", "Why", "Unless You Do It Again", "Away in the Manger / Coventry Carol", "Love Bath", "Love Is The Light", "So Bad", "First Time on a Ferris Wheel (Love Theme From \\\"Berry Gordy's The Last Dragon\\\")", "Just a Touch Away", "Tracks Of My Tears (Live)", "Just To See Her Again", "You Don't Know What It's Like", "Crusin'", "I Want You Back", "Some People Will Do Anything for Love", "Will You Love Me Tomorrow?", "Be Who You Are", "Asleep on My Love", "I Love The Nearness Of You", "I Can\u2019t Stand to See You Cry (Stereo Promo version)", "We\u2019ve Come Too Far to End It Now", "The Agony and the Ecstasy", "It's A Good Night", "Love Letters", "Deck the Halls", "Whatcha Gonna Do", "Holly", "Come by Here (Kum Ba Ya)", "I'll Keep My Light In My Window", "Quiet Storm (single version)", "Yester Love", "Same Old Love", "I Can\u2019t Stand to See You Cry (Commercial version)", "Christmas Greeting", "Be Kind to the Growing Mind", "Going to a Go-Go", "Melody Man", "Night and Day", "Tracks of My Tears", "Sleepless Nights", "You Are So Beautiful (feat. Dave Koz)", "Let Me Be The Clock", "A Silent Partner in a Three-Way Love Affair", "Love So Fine", "Medley: Never My Love / Never Can Say Goodbye", "And I Don't Love You", "Noel", "The Way You Do (The Things You Do)", "Ain't That Peculiar", "You've Really Got a Hold on Me", "Nearness of You", "Time After Time", "Tears of a Sweet Free Clown", "Train of Thought", "Wanna Know My Mind", "Love Don't Give No Reason", "Baby That's Backatcha", "Let Your Light Shine On Me", "Easy", "Can't Fight Love", "She's Only a Baby Herself", "More Love", "Te Quiero Como Si No Hubiera Un Manana", "(It's The) Same Old Love", "Hanging on by a Thread", "Our Love Is Here to Stay", "My Girl", "Double Good Everything", "Little Girl, Little Girl", "Tears of a Clown", "Open", "The Tracks Of My Tears", "Mickey's Monkey", "I Praise & Worship You Father", "Standing On Jesus", "Jingle Bells", "It's Christmas Time", "More Than You Know", "Girl I'm Standing There", "Heavy On Pride (Light On Love)", "Winter Wonderland", "Did You Know (Berry's Theme)", "Save Me", "One Heartbeat", "The Tracks of My Tears (live)", "In My Corner", "Wishful Thinking", "Ebony Eyes", "One Time", "Food For Thought"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-98", "prediction": ["# Reasoning Path:\nJohn F. Kennedy\n# Answer:\nJohn F. Kennedy"], "ground_truth": ["Lyndon B. Johnson"], "ans_acc": 0.0, "ans_hit": 0, "ans_f1": 0, "ans_precission": 0.0, "ans_recall": 0.0, "path_f1": 0, "path_precision": 0.0, "path_recall": 0.0, "path_ans_f1": 0, "path_ans_precision": 0.0, "path_ans_recall": 0.0}
{"id": "WebQTest-99", "prediction": ["# Reasoning Path:\nSerbia\n# Answer:\nSerbian language", "# Reasoning Path:\nSerbia -> location.country.official_language -> Serbian language\n# Answer:\nSerbian language"], "ground_truth": ["Serbian language"], "ans_acc": 1.0, "ans_hit": 1, "ans_f1": 1.0, "ans_precission": 1.0, "ans_recall": 1.0, "path_f1": 0.6666666666666666, "path_precision": 0.5, "path_recall": 1.0, "path_ans_f1": 0.6666666666666666, "path_ans_precision": 0.5, "path_ans_recall": 1.0}
